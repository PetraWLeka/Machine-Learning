{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b68dac83-6dd2-4c7a-b5e2-fd0adc0e7550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.image import resize\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#import ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d74f3a80-87a0-4bd2-b4c0-d56c3c93494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#buat data audio jadi digital trs simpan ke csv\n",
    "\n",
    "data_dir = r'C:\\kuliah\\semester 6\\ilmu data 1\\Proyek deteksi teriak\\data_paper\\Raw Audio'\n",
    "classes = ['scream', 'non_scream']\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(data_dir, classes, target_shape=(128, 128)):\n",
    "    mel_data = []\n",
    "    zcr_data = []\n",
    "    labels = []\n",
    "\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename.endswith('.wav'):\n",
    "                file_path = os.path.join(class_dir, filename)\n",
    "                audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
    "                # Perform preprocessing (e.g., convert to Mel spectrogram and resize)\n",
    "                mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
    "                mel_spectrogram = resize(np.expand_dims(mel_spectrogram, axis=-1), target_shape)\n",
    "                mel_data.append(mel_spectrogram)\n",
    "                \n",
    "                # Calculate ZCR\n",
    "                zcr = librosa.feature.zero_crossing_rate(y=audio_data)\n",
    "                zcr = resize(np.expand_dims(zcr, axis=-1), target_shape)\n",
    "                zcr_data.append(zcr)\n",
    "\n",
    "                labels.append(class_name)\n",
    "\n",
    "    return np.array(mel_data), np.array(zcr_data), np.array(labels)\n",
    "\n",
    "\n",
    "data, zcr_data, labels = load_and_preprocess_data(data_dir, classes)\n",
    "\n",
    "# Save Mel spectrogram data to a file\n",
    "np.save('mel_data.npy', data)\n",
    "\n",
    "# Save ZCR data to a file\n",
    "np.save('zcr_data.npy', zcr_data)\n",
    "\n",
    "# Save labels to a file\n",
    "np.savetxt('labels.csv', labels, fmt='%s')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44d107fa-c694-499a-93f6-c7083c850784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jalankan kode dari sini, tidak usah buat baca ulang data audio 600mb lebih\n",
    "# Load data and labels from CSV files\n",
    "#bisa dibuat jadi pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data = np.load('mel_data.npy')\n",
    "labels = np.loadtxt('labels.csv', dtype=str)\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf57f6dd-bb6b-408d-988c-80b03f3fa570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels:\n",
      "scream non_scream\n",
      "Encoded labels:\n",
      "1 0\n"
     ]
    }
   ],
   "source": [
    "# Load data and labels from CSV files\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Print original labels before encoding\n",
    "print(\"Original labels:\")\n",
    "print(labels[0], labels[-1])\n",
    "\n",
    "# Convert labels to integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Print encoded labels\n",
    "print(\"Encoded labels:\")\n",
    "print(labels_encoded[0], labels_encoded[-1])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train_encoded, y_test_encoded = train_test_split(data, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert integer labels to one-hot encoding\n",
    "num_classes = len(classes)\n",
    "y_train = to_categorical(y_train_encoded, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test_encoded, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec6940c8-7961-4af3-98d5-ceb2a7af6983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(869, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6cb3b27-f1cb-4439-b9a6-207724bd6778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "22/22 [==============================] - 5s 195ms/step - loss: 13.5048 - accuracy: 0.7914 - val_loss: 0.3905 - val_accuracy: 0.9655\n",
      "Epoch 2/30\n",
      "22/22 [==============================] - 4s 169ms/step - loss: 0.1545 - accuracy: 0.9827 - val_loss: 0.0958 - val_accuracy: 0.9828\n",
      "Epoch 3/30\n",
      "22/22 [==============================] - 4s 172ms/step - loss: 0.0347 - accuracy: 0.9928 - val_loss: 0.1027 - val_accuracy: 0.9828\n",
      "Epoch 4/30\n",
      "22/22 [==============================] - 4s 186ms/step - loss: 0.0484 - accuracy: 0.9928 - val_loss: 0.1689 - val_accuracy: 0.9770\n",
      "Epoch 5/30\n",
      "22/22 [==============================] - 4s 198ms/step - loss: 0.0175 - accuracy: 0.9928 - val_loss: 0.0989 - val_accuracy: 0.9885\n",
      "Epoch 6/30\n",
      "22/22 [==============================] - 4s 181ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9885\n",
      "Epoch 7/30\n",
      "22/22 [==============================] - 4s 164ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9885\n",
      "Epoch 8/30\n",
      "22/22 [==============================] - 4s 163ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 0.9885\n",
      "Epoch 9/30\n",
      "22/22 [==============================] - 4s 172ms/step - loss: 7.5215e-04 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9885\n",
      "Epoch 10/30\n",
      "22/22 [==============================] - 4s 170ms/step - loss: 5.6933e-04 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9885\n",
      "Epoch 11/30\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 4.5472e-04 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 0.9885\n",
      "Epoch 12/30\n",
      "22/22 [==============================] - 4s 176ms/step - loss: 3.6148e-04 - accuracy: 1.0000 - val_loss: 0.0827 - val_accuracy: 0.9828\n",
      "Epoch 13/30\n",
      "22/22 [==============================] - 4s 189ms/step - loss: 2.9636e-04 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9828\n",
      "Epoch 14/30\n",
      "22/22 [==============================] - 4s 186ms/step - loss: 2.4474e-04 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9828\n",
      "Epoch 15/30\n",
      "22/22 [==============================] - 4s 168ms/step - loss: 2.0107e-04 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9828\n",
      "Epoch 16/30\n",
      "22/22 [==============================] - 4s 162ms/step - loss: 1.6621e-04 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9828\n",
      "Epoch 17/30\n",
      "22/22 [==============================] - 4s 167ms/step - loss: 1.3935e-04 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9828\n",
      "Epoch 18/30\n",
      "22/22 [==============================] - 4s 181ms/step - loss: 1.1774e-04 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9828\n",
      "Epoch 19/30\n",
      "22/22 [==============================] - 4s 170ms/step - loss: 9.7782e-05 - accuracy: 1.0000 - val_loss: 0.1200 - val_accuracy: 0.9828\n",
      "Epoch 20/30\n",
      "22/22 [==============================] - 3s 157ms/step - loss: 8.2020e-05 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9828\n",
      "Epoch 21/30\n",
      "22/22 [==============================] - 4s 165ms/step - loss: 5.5385e-05 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9828\n",
      "Epoch 22/30\n",
      "22/22 [==============================] - 4s 198ms/step - loss: 4.2673e-05 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9828\n",
      "Epoch 23/30\n",
      "22/22 [==============================] - 4s 182ms/step - loss: 3.6174e-05 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9828\n",
      "Epoch 24/30\n",
      "22/22 [==============================] - 3s 156ms/step - loss: 2.9648e-05 - accuracy: 1.0000 - val_loss: 0.1458 - val_accuracy: 0.9828\n",
      "Epoch 25/30\n",
      "22/22 [==============================] - 4s 162ms/step - loss: 2.4794e-05 - accuracy: 1.0000 - val_loss: 0.1493 - val_accuracy: 0.9828\n",
      "Epoch 26/30\n",
      "22/22 [==============================] - 3s 155ms/step - loss: 2.0758e-05 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9828\n",
      "Epoch 27/30\n",
      "22/22 [==============================] - 4s 181ms/step - loss: 1.7810e-05 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9828\n",
      "Epoch 28/30\n",
      "22/22 [==============================] - 3s 157ms/step - loss: 1.5109e-05 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9828\n",
      "Epoch 29/30\n",
      "22/22 [==============================] - 4s 167ms/step - loss: 1.2734e-05 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9828\n",
      "Epoch 30/30\n",
      "22/22 [==============================] - 4s 172ms/step - loss: 1.0719e-05 - accuracy: 1.0000 - val_loss: 0.1673 - val_accuracy: 0.9828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d1cb1d9a80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Algoritma pertama, coba buat dengan cnn untuk baca grafik mel spectogram\n",
    "input_shape = X_train[0].shape\n",
    "input_layer = Input(shape=input_shape)\n",
    "x = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output_layer = Dense(len(classes), activation='softmax')(x)\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "# Step 5: Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 6: Train the model\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4a45d56-04c3-41c6-8bcb-848f816d3edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.982758641242981\n",
      "6/6 [==============================] - 0s 38ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non_scream       0.99      0.98      0.99       112\n",
      "      scream       0.97      0.98      0.98        62\n",
      "\n",
      "    accuracy                           0.98       174\n",
      "   macro avg       0.98      0.98      0.98       174\n",
      "weighted avg       0.98      0.98      0.98       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Map class indices to class labels\n",
    "class_labels = {0: 'non_scream', 1: 'scream'}\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Predict labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Convert one-hot encoded labels back to original labels\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Generate classification report with class labels\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=[class_labels[i] for i in range(len(class_labels))]))\n",
    "\n",
    "# Save the model\n",
    "model.save('cnn_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48759e52-02c8-4630-a723-4908e19072a2",
   "metadata": {},
   "source": [
    "### Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "840c9982-2138-4a97-a8da-7d31aa071b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jalankan kode dari sini, tidak usah buat baca ulang data audio 600mb lebih\n",
    "# Load data and labels from CSV files\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "mel_data = np.load('mel_data.npy')\n",
    "zcr_data = np.load('zcr_data.npy')\n",
    "labels = np.loadtxt('labels.csv', dtype=str)\n",
    "# Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "25ca3a7e-9865-4c9e-8ccd-f729ff3cbd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bisa diubah jadi pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Load Mel spectrogram data, ZCR data, and labels\n",
    "mel_data = np.load('mel_data.npy')\n",
    "zcr_data = np.load('zcr_data.npy')\n",
    "labels = np.loadtxt('labels.csv', dtype=str)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Flatten Mel spectrogram data and ZCR data\n",
    "mel_data_flat = mel_data.reshape(mel_data.shape[0], -1)\n",
    "zcr_data_flat = zcr_data.reshape(zcr_data.shape[0], -1)\n",
    "\n",
    "# Combine flattened Mel spectrogram data and ZCR data\n",
    "X_combined_flat = np.concatenate((mel_data_flat, zcr_data_flat), axis=1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined_flat, labels_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "745e097d-e08f-4dd9-adb2-347466705c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9712643678160919\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       112\n",
      "           1       0.97      0.95      0.96        62\n",
      "\n",
      "    accuracy                           0.97       174\n",
      "   macro avg       0.97      0.97      0.97       174\n",
      "weighted avg       0.97      0.97      0.97       174\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\PythonIlmuData1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create and train logistic regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for testing set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Generate classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5335f8e4-a386-429d-87f7-3cd5aade51cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_model.joblib']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Define the filename for saving the model\n",
    "logistic_model_filename = 'logistic_regression_model.joblib'\n",
    "\n",
    "# Save the logistic regression model to a file\n",
    "dump(log_reg, logistic_model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0432d0a5-3daf-47ab-bf4f-a8d9f482b543",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Kalau mau load model biar tidak train ulang\n",
    "from joblib import load\n",
    "\n",
    "# Load the saved model from file\n",
    "loaded_model = load('svm_model.joblib')\n",
    "\n",
    "# Now you can use the loaded model for predictions\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f88a668-6914-4d0b-b7ad-3ff5c8fc71be",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8b56247-ac1d-4e6f-8b32-dc8a3968e7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 100, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Reshape the input data for SVM\n",
    "# X_train_flattened = X_train.reshape(X_train.shape[0], -1)\n",
    "# X_test_flattened = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'C': [0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# Initialize SVM model\n",
    "svm_model = SVC()\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e303221-a1f5-4b46-ae00-abc40d34645d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9712643678160919\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      scream       0.98      0.97      0.98       112\n",
      "  non_scream       0.95      0.97      0.96        62\n",
      "\n",
      "    accuracy                           0.97       174\n",
      "   macro avg       0.97      0.97      0.97       174\n",
      "weighted avg       0.97      0.97      0.97       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with best parameters\n",
    "best_svm_model = SVC(**best_params)\n",
    "best_svm_model.fit(X_train, y_train)\n",
    "y_pred = best_svm_model.predict(X_test)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54765b1-e63d-4ee8-8ea7-d4b6d96f75bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Define the filename for saving the model\n",
    "model_filename = 'svm_model.joblib'\n",
    "\n",
    "# Save the model to a file\n",
    "dump(best_svm_model, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9476ecc6-52a1-4973-9d49-f29af60c2be4",
   "metadata": {},
   "source": [
    "### Bandingkan semua model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "98d8073c-39b8-483e-a24a-9cde9a850fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels:\n",
      "scream non_scream\n",
      "Encoded labels:\n",
      "1 0\n",
      "CNN model\n",
      "Test Accuracy: 0.982758641242981\n",
      "6/6 [==============================] - 0s 36ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non_scream       0.99      0.98      0.99       112\n",
      "      scream       0.97      0.98      0.98        62\n",
      "\n",
      "    accuracy                           0.98       174\n",
      "   macro avg       0.98      0.98      0.98       174\n",
      "weighted avg       0.98      0.98      0.98       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from joblib import load\n",
    "from keras.models import load_model\n",
    "#jalankan kode dari sini, tidak usah buat baca ulang data audio 600mb lebih\n",
    "# Load data and labels from CSV files\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data = np.load('mel_data.npy')\n",
    "labels = np.loadtxt('labels.csv', dtype=str)\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load data and labels from CSV files\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Print original labels before encoding\n",
    "print(\"Original labels:\")\n",
    "print(labels[0], labels[-1])\n",
    "\n",
    "# Convert labels to integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Print encoded labels\n",
    "print(\"Encoded labels:\")\n",
    "print(labels_encoded[0], labels_encoded[-1])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train_encoded, y_test_encoded = train_test_split(data, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert integer labels to one-hot encoding\n",
    "num_classes = len(classes)\n",
    "y_train = to_categorical(y_train_encoded, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test_encoded, num_classes=num_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the saved model from file\n",
    "model = load_model('cnn_model.h5')\n",
    "print('CNN model')\n",
    "# Map class indices to class labels\n",
    "class_labels = {0: 'non_scream', 1: 'scream'}\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Predict labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Convert one-hot encoded labels back to original labels\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Generate classification report with class labels\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=[class_labels[i] for i in range(len(class_labels))]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c76c3f0-a4b5-4eed-bf67-ca541ea83b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model\n",
      "Test Accuracy: 0.9712643678160919\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       112\n",
      "           1       0.97      0.95      0.96        62\n",
      "\n",
      "    accuracy                           0.97       174\n",
      "   macro avg       0.97      0.97      0.97       174\n",
      "weighted avg       0.97      0.97      0.97       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load Mel spectrogram data, ZCR data, and labels\n",
    "mel_data = np.load('mel_data.npy')\n",
    "zcr_data = np.load('zcr_data.npy')\n",
    "labels = np.loadtxt('labels.csv', dtype=str)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Flatten Mel spectrogram data and ZCR data\n",
    "mel_data_flat = mel_data.reshape(mel_data.shape[0], -1)\n",
    "zcr_data_flat = zcr_data.reshape(zcr_data.shape[0], -1)\n",
    "\n",
    "# Combine flattened Mel spectrogram data and ZCR data\n",
    "X_combined_flat = np.concatenate((mel_data_flat, zcr_data_flat), axis=1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined_flat, labels_encoded, test_size=0.2, random_state=42)\n",
    "log_reg = load('logistic_regression_model.joblib')\n",
    "print('Logistic regression model')\n",
    "\n",
    "# Predict labels for testing set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Generate classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef919842-f7d8-4ad0-927b-53ab5ba4b419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9712643678160919\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      scream       0.98      0.97      0.98       112\n",
      "  non_scream       0.95      0.97      0.96        62\n",
      "\n",
      "    accuracy                           0.97       174\n",
      "   macro avg       0.97      0.97      0.97       174\n",
      "weighted avg       0.97      0.97      0.97       174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with best parameters\n",
    "best_svm_model = load('svm_model.joblib')\n",
    "y_pred = best_svm_model.predict(X_test)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred, target_names=classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e656f3f55dd8b6463f9fa0d4fcd0ebcd8685aa7126a00c9452d28f5335cd60f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
